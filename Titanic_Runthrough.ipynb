{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Prepare for work\n",
    "#### 1.1 Load Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load packages\n",
    "import sys #access to system parameters https://docs.python.org/3/library/sys.html\n",
    "print(\"Python version: {}\". format(sys.version))\n",
    "\n",
    "import pandas as pd #collection of functions for data processing and analysis modeled after R dataframes with SQL like features\n",
    "print(\"pandas version: {}\". format(pd.__version__))\n",
    "\n",
    "import matplotlib #collection of functions for scientific and publication-ready visualization\n",
    "print(\"matplotlib version: {}\". format(matplotlib.__version__))\n",
    "\n",
    "import numpy as np #foundational package for scientific computing\n",
    "print(\"NumPy version: {}\". format(np.__version__))\n",
    "\n",
    "import scipy as sp #collection of functions for scientific computing and advance mathematics\n",
    "print(\"SciPy version: {}\". format(sp.__version__)) \n",
    "\n",
    "import IPython\n",
    "from IPython import display #pretty printing of dataframes in Jupyter notebook\n",
    "print(\"IPython version: {}\". format(IPython.__version__)) \n",
    "\n",
    "import sklearn #collection of machine learning algorithms\n",
    "print(\"scikit-learn version: {}\". format(sklearn.__version__))\n",
    "\n",
    "#misc libraries\n",
    "import random\n",
    "import time\n",
    "\n",
    "#ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "print('-'*25)\n",
    "\n",
    "#Common Model Algorithms\n",
    "from sklearn import svm, tree, linear_model, neighbors, naive_bayes, ensemble, discriminant_analysis, gaussian_process\n",
    "####---- from xgboost import XGBClassifier\n",
    "\n",
    "#Common Model Helpers\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "from sklearn import feature_selection\n",
    "from sklearn import model_selection\n",
    "from sklearn import metrics\n",
    "\n",
    "#Visualization\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.pylab as pylab\n",
    "import seaborn as sns\n",
    "# from pandas.tools.plotting import scatter_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "from sklearn.metrics import classification_report, accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2 Configure Viz defaults"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "mpl.style.use('ggplot')\n",
    "sns.set_style('white')\n",
    "pylab.rcParams['figure.figsize'] = 12,8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.3 Check input data directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from subprocess import check_output\n",
    "print(check_output([\"ls\", \"./data\"]).decode(\"utf8\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2 Wrangling Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1 Get from GCS bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!gsutil cp gs://bbs-2019-aiml4b-base-mldata/gender_submission.csv ./02.titanic/data\n",
    "!gsutil cp gs://bbs-2019-aiml4b-base-mldata/train.csv ./02.titanic/data\n",
    "!gsutil cp gs://bbs-2019-aiml4b-base-mldata/test.csv ./02.titanic/data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2 Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_raw = pd.read_csv('./data/train.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2.2.1 Data Attributes (structure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (data_raw.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### An explanation of attributes (features?)\n",
    "\n",
    "##### PASSENGER ID\n",
    "Some code for the passenger into Titanic's *information system*. It's like the Employee ID in your company!\n",
    "\n",
    "##### TICKET\n",
    "The ticket number / code\n",
    "\n",
    "##### PCLASS\n",
    "Ordinal variable\n",
    " - 1: upper class\n",
    " - 2: middle class\n",
    " - 3: lower class\n",
    "\n",
    "##### NAME, SEX, AGE\n",
    "It's the NAME, AGE and SEX of the passenger!\n",
    "\n",
    "##### EMBARKED\n",
    "The Port where the passenger was embarked\n",
    "\n",
    "##### FARE\n",
    "It's the fare paid by the passenger for the ticket\n",
    "\n",
    "##### SIBSP\n",
    "Represents number of related siblings/spouse aboard\n",
    "\n",
    "##### PARCH\n",
    "Represents number of related parents/children aboard\n",
    "\n",
    "##### CABIN\n",
    "Kind of approximate position on ship when the incident occurred\n",
    "\n",
    "##### SURVIVED\n",
    "It's the *label*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2.2.2 Data Preview (10 records)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_raw.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2.2.3 Statistical Properties Overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_raw.describe(include = 'all')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3 Set Training and Validation Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_val  = pd.read_csv('./data/test.csv')\n",
    "data_train = data_raw.copy(deep = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1 Investigating on NULLs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Train columns with null values:\\n', data_train.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4 Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.1 Fill missing AGE with *median* value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train['Age'].fillna(data_train['Age'].median(), inplace = True)\n",
    "data_val['Age'].fillna(data_val['Age'].median(), inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2 Fill missing EMBARKED with *mode* value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train['Embarked'].fillna(data_train['Embarked'].mode()[0], inplace = True)\n",
    "data_val['Embarked'].fillna(data_val['Embarked'].mode()[0], inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.3 Fill missing FARE with *median* value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train['Fare'].fillna(data_train['Fare'].median(), inplace = True)\n",
    "data_val['Fare'].fillna(data_val['Fare'].median(), inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.4 Discard useless features\n",
    " - Passenger ID\n",
    " - Cabin (Code)\n",
    " - Ticket (Number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_column = ['PassengerId', 'Cabin', 'Ticket']\n",
    "data_train.drop(drop_column, axis=1, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.4 Checking NULLs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data_train.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5 Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.1 FamilySize\n",
    "Calculated field that comes from summing up the passenger itself, its siblings/spouse and its parents/children aboard with it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train['FamilySize'] = data_train['SibSp'] + data_train['Parch'] + 1\n",
    "data_val['FamilySize'] = data_val['SibSp'] + data_val['Parch'] + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.2 IsAlone\n",
    "One more \"calculation\" to mark which passengers were travelling alone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train['IsAlone'] = 1\n",
    "data_train['IsAlone'].loc[data_train['FamilySize'] > 1] = 0\n",
    "\n",
    "data_val['IsAlone'] = 1\n",
    "data_val['IsAlone'].loc[data_val['FamilySize'] > 1] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.3 Title\n",
    "\n",
    "NAME variable is formattes as \\<Surname\\>, \\<Title\\>. \\<Name\\>.\n",
    "Let's isolate the \"Title\" token."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train['Title'] = data_train['Name'].str.split(\", \", expand=True)[1].str.split(\".\", expand=True)[0]\n",
    "data_val['Title'] = data_val['Name'].str.split(\", \", expand=True)[1].str.split(\".\", expand=True)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 5.6.1 Rare values\n",
    "\n",
    "They call it the *Long Tail*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data_train['Title'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train['Title'].value_counts().hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10 is a magic number (http://nicholasjjackson.com/2012/03/08/sample-size-is-10-a-magic-number/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title_names = (data_train['Title'].value_counts() < 10)\n",
    "data_train['Title'] = data_train['Title'].apply(lambda x: 'Misc' if title_names.loc[x] == True else x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check our work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data_train['Title'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.4 Checkup!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.5 FARE\n",
    "\n",
    "FARE variable is continuous but we consider it quantizable into 4 bins to reduce complexity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train['Fare'].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train['FareBin'] = pd.qcut(data_train['Fare'], 4)\n",
    "data_val['FareBin'] = pd.qcut(data_val['Fare'], 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.6 AGE\n",
    "\n",
    "Doing the same on AGE into 5 bins (we need integer bins here!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train['Age'].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train['AgeBin'] = pd.cut(data_train['Age'].astype(int), 5)\n",
    "data_val['AgeBin'] = pd.cut(data_val['Age'].astype(int), 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.7 Let's check it up again!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6 Feature Engineering: CATEGORICAL data\n",
    "\n",
    "LabelEncoder is aimed to transform \"list of alphanumeric values\" into a numeric (integer) mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = LabelEncoder()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transform in numeric the following attributes\n",
    " - SEX\n",
    " - Embarked\n",
    " - Title\n",
    " - Age  (quantized)\n",
    " - Fare (quantized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train['Sex_Code'] = label.fit_transform(data_train['Sex'])\n",
    "data_train['Embarked_Code'] = label.fit_transform(data_train['Embarked'])\n",
    "data_train['Title_Code'] = label.fit_transform(data_train['Title'])\n",
    "data_train['AgeBin_Code'] = label.fit_transform(data_train['AgeBin'])\n",
    "data_train['FareBin_Code'] = label.fit_transform(data_train['FareBin'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_val['Sex_Code'] = label.fit_transform(data_val['Sex'])\n",
    "data_val['Embarked_Code'] = label.fit_transform(data_val['Embarked'])\n",
    "data_val['Title_Code'] = label.fit_transform(data_val['Title'])\n",
    "data_val['AgeBin_Code'] = label.fit_transform(data_val['AgeBin'])\n",
    "data_val['FareBin_Code'] = label.fit_transform(data_val['FareBin'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train['FareBin_Code'].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train['AgeBin_Code'].hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8 Assessing X-Correlation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def correlation_heatmap(df):\n",
    "    _ , ax = plt.subplots(figsize =(14, 12))\n",
    "    colormap = sns.diverging_palette(220, 10, as_cmap = True)\n",
    "    \n",
    "    _ = sns.heatmap(\n",
    "        df.corr(), \n",
    "        cmap = colormap,\n",
    "        square=True, \n",
    "        cbar_kws={'shrink':.9 }, \n",
    "        ax=ax,\n",
    "        annot=True, \n",
    "        linewidths=0.1,vmax=1.0, linecolor='white',\n",
    "        annot_kws={'fontsize':12 }\n",
    "    )\n",
    "    \n",
    "    plt.title('Correlation of Features (Pearson)', y=1.05, size=15)\n",
    "\n",
    "correlation_heatmap(data_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7 Preparing for ML\n",
    "\n",
    "Mark the LABEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Target = ['Survived']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7.1 Features selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train_x_bin = ['Sex_Code','Pclass', 'Embarked_Code', 'Title_Code', 'FamilySize', 'AgeBin_Code', 'FareBin_Code']\n",
    "data_train_xy_bin = Target + data_train_x_bin\n",
    "print('Bin X Y: ', data_train_xy_bin, '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7.2 Split Train and Test Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train1_x_bin, test1_x_bin, train1_y_bin, test1_y_bin = model_selection.train_test_split(data_train[data_train_x_bin], data_train[Target] , random_state = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train1_x_bin.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9 ML\n",
    "\n",
    "Support Vector Machines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV#, train_test_split\n",
    "\n",
    "param_grid = [{'kernel': ['rbf'], 'C': [10, 100, 1000], 'gamma' : [1e-2, 1e-3, 1e-4]},\n",
    "              {'kernel': ['linear'], 'C': [1, 10, 100]}]\n",
    "\n",
    "#X_train_a, X_train_v, Y_train_a, Y_train_v = train_test_split(X_train, Y_train, random_state=42)\n",
    "gcv = GridSearchCV(svm.SVC(), param_grid, cv=5, n_jobs=4)\n",
    "gcv.fit(train1_x_bin, train1_y_bin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mu = gcv.cv_results_['mean_test_score']\n",
    "std = gcv.cv_results_['std_test_score']\n",
    "pars = gcv.cv_results_['params']\n",
    "for (m,s,p) in zip(mu,std,pars):\n",
    "    print('%.2f (+-%.2f): %s' %(m,s,p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = gcv.predict(test1_x_bin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('hyperparams: %s' % gcv.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(pred,test1_y_bin))\n",
    "print('accuracy %.2f' % accuracy_score(pred,test1_y_bin))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CONFUSION MATRIX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot Accuracy Summary\n",
    "#Credit: http://scikit-learn.org/stable/auto_examples/model_selection/plot_confusion_matrix.html\n",
    "import itertools\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "\n",
    "# Compute confusion matrix\n",
    "cnf_matrix = metrics.confusion_matrix(test1_y_bin, pred)\n",
    "np.set_printoptions(precision=2)\n",
    "\n",
    "class_names = ['Dead', 'Survived']\n",
    "# Plot non-normalized confusion matrix\n",
    "plt.figure()\n",
    "plot_confusion_matrix(cnf_matrix, classes=class_names,\n",
    "                      title='Confusion matrix, without normalization')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot normalized confusion matrix\n",
    "plt.figure()\n",
    "plot_confusion_matrix(cnf_matrix, classes=class_names, normalize=True, \n",
    "                      title='Normalized confusion matrix')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}